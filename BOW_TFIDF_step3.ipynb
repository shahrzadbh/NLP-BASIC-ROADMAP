{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "SPpK2X4Mc1Jj"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFG8DKxZe7sR",
        "outputId": "6557c14d-7fc9-45ae-b5ac-781bfe5cca22"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"A major drawback of statistical methods is that they require elaborate feature engineering.\n",
        "Since the early 2010s, the field has thus largely abandoned statistical methods and shifted to neural networks for machine learning.\n",
        "Popular techniques include the use of word embeddings to capture semantic properties of words, and an increase in end-to-end learning of a higher-level task (e.g., question answering) instead of relying on a pipeline of separate intermediate tasks (e.g., part-of-speech tagging and dependency parsing).\n",
        "In some areas, this shift has entailed substantial changes in how NLP systems are designed, such that deep neural network-based approaches may be viewed as a new paradigm distinct from statistical natural language processing.\n",
        "For instance, the term neural machine translation (NMT) emphasizes the fact that deep learning-based approaches to machine translation directly learn sequence-to-sequence transformations, obviating the need for intermediate steps such as word alignment and language modeling that was used in statistical machine translation (SMT).\n",
        "Latest works tend to use non-technical structure of a given task to build proper neural network\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "67SN4x0tdF94"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences =sent_tokenize(text)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "corpus = []\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "\n",
        "for token in sentences :\n",
        "  review = re.sub('[^a-zA-Z]',' ',token)\n",
        "  review = re.sub(\"\\b[a-zA-Z]\\b\", \" \", review)\n",
        "  review = review.lower()\n",
        "  review = word_tokenize(review)\n",
        "  review = [token for token in review if token not in stop_words]\n",
        "  review = [stemmer.stem(token) for token in review]\n",
        "  review = \" \".join(review)\n",
        "  corpus.append(review)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBp0FfRfdN2c",
        "outputId": "68c453bb-8d4c-4a9f-c5e4-7fd386de9cd7"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['major drawback statist method requir elabor featur engin']\n",
            "['major drawback statist method requir elabor featur engin', 'sinc earli field thu larg abandon statist method shift neural network machin learn']\n",
            "['major drawback statist method requir elabor featur engin', 'sinc earli field thu larg abandon statist method shift neural network machin learn', 'popular techniqu includ use word embed captur semant properti word increas end end learn higher level task e g question answer instead reli pipelin separ intermedi task e g part speech tag depend pars']\n",
            "['major drawback statist method requir elabor featur engin', 'sinc earli field thu larg abandon statist method shift neural network machin learn', 'popular techniqu includ use word embed captur semant properti word increas end end learn higher level task e g question answer instead reli pipelin separ intermedi task e g part speech tag depend pars', 'area shift entail substanti chang nlp system design deep neural network base approach may view new paradigm distinct statist natur languag process']\n",
            "['major drawback statist method requir elabor featur engin', 'sinc earli field thu larg abandon statist method shift neural network machin learn', 'popular techniqu includ use word embed captur semant properti word increas end end learn higher level task e g question answer instead reli pipelin separ intermedi task e g part speech tag depend pars', 'area shift entail substanti chang nlp system design deep neural network base approach may view new paradigm distinct statist natur languag process', 'instanc term neural machin translat nmt emphas fact deep learn base approach machin translat directli learn sequenc sequenc transform obviat need intermedi step word align languag model use statist machin translat smt']\n",
            "['major drawback statist method requir elabor featur engin', 'sinc earli field thu larg abandon statist method shift neural network machin learn', 'popular techniqu includ use word embed captur semant properti word increas end end learn higher level task e g question answer instead reli pipelin separ intermedi task e g part speech tag depend pars', 'area shift entail substanti chang nlp system design deep neural network base approach may view new paradigm distinct statist natur languag process', 'instanc term neural machin translat nmt emphas fact deep learn base approach machin translat directli learn sequenc sequenc transform obviat need intermedi step word align languag model use statist machin translat smt', 'latest work tend use non technic structur given task build proper neural network']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "vectorization"
      ],
      "metadata": {
        "id": "DHvPzJDCtqkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer()\n",
        "bow = cv.fit_transform(corpus).toarray()"
      ],
      "metadata": {
        "id": "LnghhGUwtnPy"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFR4mKrZuNhM",
        "outputId": "7aa9c5b7-84a4-4741-c80d-1d2dfd063fba"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0,\n",
              "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
              "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0,\n",
              "        0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
              "        0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 1, 0, 2, 0],\n",
              "       [0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "        1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "        0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 2, 0, 3, 0, 0, 0, 1, 0, 1,\n",
              "        0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,\n",
              "        0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 3, 1, 0, 1, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tf = TfidfVectorizer()\n",
        "tfidf = tf.fit_transform(corpus).toarray()"
      ],
      "metadata": {
        "id": "z0XaA_ZJuroJ"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnmV0oXZutBs",
        "outputId": "29596822-3ece-4890-aa0f-31c53dd3bc8c"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.37730799,\n",
              "        0.        , 0.37730799, 0.        , 0.        , 0.        ,\n",
              "        0.37730799, 0.        , 0.        , 0.37730799, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.37730799, 0.        ,\n",
              "        0.30939795, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.37730799, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.22384142,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        ],\n",
              "       [0.32141589, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.32141589, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.32141589,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.32141589, 0.        ,\n",
              "        0.22252021, 0.        , 0.26356563, 0.        , 0.        ,\n",
              "        0.26356563, 0.        , 0.        , 0.        , 0.22252021,\n",
              "        0.19068292, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.26356563, 0.32141589, 0.        , 0.        , 0.19068292,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.32141589, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.17674796, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.17674796, 0.        , 0.        ,\n",
              "        0.17674796, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.17674796, 0.        , 0.35349593,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.17674796, 0.17674796, 0.17674796, 0.        ,\n",
              "        0.17674796, 0.14493586, 0.        , 0.        , 0.        ,\n",
              "        0.12236481, 0.17674796, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.17674796, 0.17674796, 0.17674796,\n",
              "        0.17674796, 0.        , 0.        , 0.17674796, 0.17674796,\n",
              "        0.17674796, 0.        , 0.17674796, 0.17674796, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.17674796, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.17674796,\n",
              "        0.28987172, 0.        , 0.17674796, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.12236481, 0.        ,\n",
              "        0.28987172, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.19041633, 0.23221098,\n",
              "        0.19041633, 0.        , 0.        , 0.23221098, 0.19041633,\n",
              "        0.        , 0.23221098, 0.        , 0.23221098, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.23221098, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.19041633, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.23221098,\n",
              "        0.        , 0.        , 0.23221098, 0.        , 0.16076255,\n",
              "        0.13776129, 0.23221098, 0.23221098, 0.        , 0.        ,\n",
              "        0.        , 0.23221098, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.23221098, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.19041633, 0.        , 0.        , 0.        , 0.13776129,\n",
              "        0.        , 0.        , 0.23221098, 0.23221098, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.23221098,\n",
              "        0.        , 0.        ],\n",
              "       [0.        , 0.15974615, 0.        , 0.13099413, 0.        ,\n",
              "        0.13099413, 0.        , 0.        , 0.        , 0.13099413,\n",
              "        0.        , 0.        , 0.15974615, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.15974615, 0.        ,\n",
              "        0.        , 0.        , 0.15974615, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.15974615,\n",
              "        0.        , 0.13099413, 0.13099413, 0.        , 0.        ,\n",
              "        0.22118848, 0.        , 0.39298238, 0.        , 0.        ,\n",
              "        0.        , 0.15974615, 0.        , 0.15974615, 0.        ,\n",
              "        0.09477086, 0.        , 0.        , 0.15974615, 0.        ,\n",
              "        0.15974615, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.31949229,\n",
              "        0.        , 0.        , 0.15974615, 0.        , 0.09477086,\n",
              "        0.15974615, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.15974615,\n",
              "        0.        , 0.15974615, 0.47923844, 0.11059424, 0.        ,\n",
              "        0.13099413, 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.30174497, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.30174497, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.30174497,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.20890179,\n",
              "        0.17901297, 0.        , 0.        , 0.        , 0.30174497,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.30174497, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.30174497, 0.        , 0.        , 0.        ,\n",
              "        0.2474352 , 0.30174497, 0.        , 0.30174497, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.20890179, 0.        ,\n",
              "        0.        , 0.30174497]])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    }
  ]
}