{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "z6or98T57LeU"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "texts = ['This is the first document', 'This document is the second document', 'And this is the third one', 'Is this the first document?']\n",
        "max_words = 20000\n",
        "max_len = 100"
      ],
      "metadata": {
        "id": "tMCU28Wj7Wt0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the texts\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "sequences = tokenizer.texts_to_sequences(texts)"
      ],
      "metadata": {
        "id": "VhVHQmhw7esb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad the sequences to a fixed length\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len)"
      ],
      "metadata": {
        "id": "tQQzklzr7nPt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the labels to categorical variables\n",
        "labels = to_categorical([0, 0, 1, 1])\n"
      ],
      "metadata": {
        "id": "DGx7EAam8A1z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, 128, input_length=max_len))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "IptVP9MZ8C90"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1_gho5YL8Nen"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "history = model.fit(padded_sequences, labels, epochs=5, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pphDg0s-8UlZ",
        "outputId": "068a04fa-0157-4790-815f-4dc9abfe581f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.7028 - accuracy: 0.2500\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 0.6846 - accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.6905 - accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.6961 - accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.7035 - accuracy: 0.0000e+00\n"
          ]
        }
      ]
    }
  ]
}