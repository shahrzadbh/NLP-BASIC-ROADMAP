{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IajlblplzEXd"
      },
      "source": [
        "an example of how to use the TensorFlow library to fine-tune a pre-trained transformer model for a text classification task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "CVqxg6acgFfT"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntN5VCzZiPeu",
        "outputId": "58de14a5-949a-4346-be57-e7ea7a7c7ba9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "#Load the pre-trained model and set the number of output classes\n",
        "model = TFBertForSequenceClassification.from_pretrained ('bert-base-uncased', num_labels = 2)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "HUM6oCvljR15"
      },
      "outputs": [],
      "source": [
        "#define input and labels\n",
        "input_data = [\"This movie was great!\", \"I did not like this movie\"]\n",
        "labels = np.array([1, 0])  # Convert labels to numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "EtoNNqzelygG"
      },
      "outputs": [],
      "source": [
        "# Tokenize the input texts\n",
        "tokenized_inputs = tokenizer(input_data, padding=True, truncation=True, return_tensors=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "lRzU1T0Jm75B"
      },
      "outputs": [],
      "source": [
        "# Convert tokenized inputs to TensorFlow tensors\n",
        "input_ids = tf.constant(tokenized_inputs['input_ids'])\n",
        "attention_mask = tf.constant(tokenized_inputs['attention_mask'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0ZD462vj2gy",
        "outputId": "92cc71b5-0f46-46c6-882a-74ee29070c43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 40s 40s/step - loss: 0.9749 - sparse_categorical_accuracy: 0.5000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e7e47006320>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fine-tune the model on the new task\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "model.fit([input_ids, attention_mask], labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "E2BI4MN5yxBN"
      },
      "outputs": [],
      "source": [
        "# Define the input text for prediction\n",
        "new_input_text = [\"This is a great book!\"]\n",
        "# Tokenize the input text\n",
        "tokenized_new_input = tokenizer(new_input_text, padding=True, truncation=True, return_tensors=\"tf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "y395dpm4y3Ay"
      },
      "outputs": [],
      "source": [
        "# Get token IDs and attention mask\n",
        "input_ids = tokenized_new_input['input_ids']\n",
        "attention_mask = tokenized_new_input['attention_mask']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7qavdO7y5zS",
        "outputId": "4548b100-ac69-4466-973c-8e28d0f44cce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "Predicted constant label: 1\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on new input data\n",
        "probabilities = model.predict([input_ids, attention_mask])[0]\n",
        "predicted_label = np.argmax(probabilities)\n",
        "\n",
        "# Assign a constant label based on the predicted_label\n",
        "constant_label = 1 if predicted_label == 1 else 0\n",
        "\n",
        "print(f\"Predicted constant label: {constant_label}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
