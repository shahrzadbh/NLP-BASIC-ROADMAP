{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Text Normalization"
      ],
      "metadata": {
        "id": "6KOptEhkdDko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"I visited the US from the UK on 22-10-18\"\n"
      ],
      "metadata": {
        "id": "qB_G4AY4c4fb"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(text):\n",
        "  return text.replace(\"US\", \"United States\").replace(\"UK\", \"United Kingdom\").replace(\"-18\", \"-2018\")"
      ],
      "metadata": {
        "id": "SqegnOwnc4Uo"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_sentence = normalize(input_text)\n",
        "print(normalized_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzBlqQ2Qc4Bp",
        "outputId": "19b647e8-92df-4ac8-e7cd-2bf005366bd4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I visited the United States from the United Kingdom on 22-10-2018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_text = normalize('US and UK are two superpowers')\n",
        "print(normalized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uI566erdtkl",
        "outputId": "9d35922d-9fe7-4517-9f44-6183276947e9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "United States and United Kingdom are two superpowers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spelling Correction of a Word and a Sentence"
      ],
      "metadata": {
        "id": "2rXM9kIWcyUH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOp4BDWDZ9Tr",
        "outputId": "5376e92a-c536-4c50-9be4-737eb1404cea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: autocorrect in /usr/local/lib/python3.10/dist-packages (2.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install autocorrect"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(['punkt'])\n",
        "from nltk import word_tokenize\n",
        "from autocorrect import Speller"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0X1pGV9DZ_Ez",
        "outputId": "3cf382a8-ccbd-41ab-9641-1c6e14e4b999"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spell = Speller(lang = 'en')\n",
        "spell('Natureal')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fxrjjGRAaUn9",
        "outputId": "88d09515-bfc0-4ef9-d0e9-a9e15a8d0047"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Natural'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Ntural Luanguage Processin deals with the art of extracting insightes from Natural Languaes\""
      ],
      "metadata": {
        "id": "DlJQiaO7aZuf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = word_tokenize(text)"
      ],
      "metadata": {
        "id": "aoBuedmabx1r"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print ('word tokenizer:',tokenizer )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWHT76X8b5Ru",
        "outputId": "4ff74da4-0e4c-4805-f793-73fdc11a334f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word tokenizer: ['Ntural', 'Luanguage', 'Processin', 'deals', 'with', 'the', 'art', 'of', 'extracting', 'insightes', 'from', 'Natural', 'Languaes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_spelling(tokens):\n",
        "  sentence_correct = ' '.join([spell(word) for word in tokens])\n",
        "\n",
        "  return sentence_correct"
      ],
      "metadata": {
        "id": "WmjZheeEcWbF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (correct_spelling(tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noTR1iJncc98",
        "outputId": "676d9082-de4a-4bf0-b616-d67c35e90f7c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural Language Processing deals with the art of extracting insights from Natural Languages\n"
          ]
        }
      ]
    }
  ]
}