{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ANpbkQtiXbES"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import fasttext\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import gutenberg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK resources (you may need to download NLTK data if not done previously)\n",
        "nltk.download('punkt')\n",
        "nltk.download('gutenberg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EjERxGDJCdz",
        "outputId": "87e1b000-d23d-47d8-96ff-0bb0711e320a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get some text data (using Gutenberg corpus as an example)\n",
        "text_corpus = \"\"\n",
        "for file_id in gutenberg.fileids():\n",
        "    text_corpus += gutenberg.raw(file_id)\n",
        "\n",
        "# Preprocessing function to clean the text\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove non-alphanumeric characters and extra spaces\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "qYq4w8rQJIEt"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the text corpus\n",
        "cleaned_text = preprocess_text(text_corpus)"
      ],
      "metadata": {
        "id": "ctXUxBcqJLgp"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize sentences and words\n",
        "sentences = sent_tokenize(cleaned_text)\n",
        "tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]"
      ],
      "metadata": {
        "id": "9qvMSKdyJO3I"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tokenized sentences to a text file\n",
        "text_data_path = 'tokenized_text.txt'"
      ],
      "metadata": {
        "id": "S78jR3R6JTRn"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(text_data_path, 'w') as text_file:\n",
        "    for sentence in tokenized_sentences:\n",
        "        text_file.write(' '.join(sentence) + '\\n')\n",
        "\n",
        "print(f\"Tokenized text data has been written to {text_data_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afUN7APjJW1v",
        "outputId": "1d8c6d50-0193-4773-b067-53b0cbff112a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized text data has been written to tokenized_text.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the FastText model\n",
        "model = fasttext.train_unsupervised(text_data_path, model='skipgram')\n",
        "\n",
        "# Save the trained model\n",
        "model.save_model('trained_model.bin')\n",
        "print(\"FastText model trained and saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bFfYLpTJcN7",
        "outputId": "28f2d660-0d42-41d4-e9b8-8943c6b1d1e1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText model trained and saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage of the trained model\n",
        "loaded_model = fasttext.load_model('trained_model.bin')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxQen1ooKoKV",
        "outputId": "52df76cd-c0c4-4c04-e9eb-b47e8c9914b1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the word vector for a specific word\n",
        "word_vector = loaded_model.get_word_vector('word')"
      ],
      "metadata": {
        "id": "O_Mw_M2gKsTI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kxb8mn5aKd8",
        "outputId": "06c037df-5bed-4499-f81b-817fa869df89"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.14741686, -0.4035446 ,  0.10212318, -0.02559507, -0.2579022 ,\n",
              "        0.4110144 ,  0.27578896, -0.12794673,  0.2722545 , -0.22372477,\n",
              "       -0.12523542,  0.40178066, -0.60799015, -0.04848578, -0.29949635,\n",
              "       -0.0416134 , -0.00498964,  0.04314872, -0.19523036,  0.37438512,\n",
              "        0.18229593, -0.30549097,  0.34077477,  0.16452955, -0.05857192,\n",
              "       -0.10769588, -0.5636373 , -0.07856709, -0.24399365, -0.20481552,\n",
              "        0.00186683, -0.1715961 , -0.5540044 , -0.17661123, -0.21138766,\n",
              "       -0.21934208, -0.26010048, -0.49465987,  0.0963107 ,  0.05410622,\n",
              "        0.16340041, -0.0926865 ,  0.2543234 ,  0.20681542,  0.25434396,\n",
              "       -0.3932816 ,  0.31264868, -0.03619537, -0.11160152, -0.02666578,\n",
              "        0.6115323 ,  0.27803785, -0.37732777, -0.6420789 ,  0.0678767 ,\n",
              "       -0.06797723, -0.3240654 , -0.3361098 ,  0.0506219 , -0.09752444,\n",
              "       -0.31721026,  0.20631003,  0.17398131, -0.61781275,  0.10100478,\n",
              "        0.36431026, -0.0202862 , -0.16360347,  0.16964242, -0.08284218,\n",
              "       -0.45213312, -0.06842587, -0.74572426,  0.200493  , -0.01777028,\n",
              "       -0.26561904,  0.49087846, -0.21193074,  0.50240666,  0.3960512 ,\n",
              "       -0.04832295,  0.10352235,  0.6105237 ,  0.03302308,  0.62486726,\n",
              "        0.05253459,  0.12718977, -0.02782032,  0.07983122,  0.00944776,\n",
              "        0.47519708, -0.6185342 ,  0.07571436,  0.32415968,  0.29815498,\n",
              "       -0.3869144 , -0.3350643 , -0.4441652 , -0.10502064,  0.35302734],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the most similar words to a given word\n",
        "similar_words = loaded_model.get_nearest_neighbors('word')\n",
        "print(\"Similar words to 'word':\", similar_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YIvGX_JaPZl",
        "outputId": "7b8bbb2e-0b9b-46d4-9f01-80850ad98d4a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similar words to 'word': [(0.7850816249847412, 'byword'), (0.7579824328422546, 'words'), (0.6917113065719604, 'syllable'), (0.6844764351844788, 'it'), (0.6827720403671265, 'spoke'), (0.6763255596160889, 'trick'), (0.6746193766593933, 'monologue'), (0.6743306517601013, 'spell'), (0.667864978313446, 'spokes'), (0.6638267636299133, 't')]\n"
          ]
        }
      ]
    }
  ]
}